{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "814b54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@ Author:         21140678-姜楠（小组成员：姜楠(21140678)、王勃栋(21140701)、李甜(21140684)）\n",
    "@ Create Date:    2021-12-01\n",
    "@ Requirements:\n",
    "1, Implmenting the naïve bayes classifier without using sk-learn.\n",
    "2, Implementation need support both discrete and continuous features, and Gaussian, Multinomial, and Bernoulli models required.\n",
    "3, Providing prediction probability is required \n",
    "4, classifier evaluation required.\n",
    "5, Compare your implementation with Sk-learn regressor.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "# 定义gaussion model\n",
    "class Gaussion:\n",
    "    def separate_by_classes(self, X, y):\n",
    "#         分类区分\n",
    "        self.classes = np.unique(y)\n",
    "        classes_index = {}\n",
    "        subdatasets = {}\n",
    "        cls, counts = np.unique(y, return_counts=True)\n",
    "        self.class_freq = dict(zip(cls, counts))\n",
    "#         print(self.class_freq)\n",
    "        for class_type in self.classes:\n",
    "            classes_index[class_type] = np.argwhere(y==class_type)\n",
    "            subdatasets[class_type] = X[classes_index[class_type], :]\n",
    "            self.class_freq[class_type] = self.class_freq[class_type]/sum(list(self.class_freq.values()))\n",
    "        return subdatasets\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        separated_X = self.separate_by_classes(X, y)\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        for class_type in self.classes:\n",
    "#             计算mean  标准偏离\n",
    "            self.means[class_type] = np.mean(separated_X[class_type], axis=0)[0]\n",
    "            self.std[class_type] = np.std(separated_X[class_type], axis=0)[0]\n",
    "            \n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.class_prob = {cls:math.log(self.class_freq[cls], math.e) for cls in self.classes}\n",
    "        for cls in self.classes:\n",
    "            for i in range(len(self.means)):\n",
    "#                 print(X[i])\n",
    "                self.class_prob[cls]+=math.log(self.calculate_probability(X[i], self.means[cls][i], self.std[cls][i]), math.e)\n",
    "        self.class_prob = {cls: math.e**self.class_prob[cls] for cls in self.class_prob}\n",
    "        return self.class_prob\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for x in X:\n",
    "            pred_class = None\n",
    "            max_prob = 0\n",
    "            for cls, prob in self.predict_proba(x).items():\n",
    "                if prob>max_prob:\n",
    "                    max_prob = prob\n",
    "                    pred_class = cls\n",
    "            pred.append(pred_class)\n",
    "        return pred\n",
    "\n",
    "# 定义Multinomial model\n",
    "class Multinomial:\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.cat0_count = 0\n",
    "        self.cat1_count = 0\n",
    "        self.total_count = self.cat0_count + self.cat1_count\n",
    "        self.cat_0_prior = 0\n",
    "        self.cat_1_prior = 0\n",
    "        self.cat_0_prior, self.cat_1_prior\n",
    "        self.word_probs = []\n",
    "        self.vocab = []\n",
    "\n",
    "    def tokenize(self, document):\n",
    "        doc = document.lower()\n",
    "        tokens = \"\"\n",
    "        for char in doc:\n",
    "            tokens += char\n",
    "        return tokens.split()\n",
    "\n",
    "    def count_words(self, X, y):\n",
    "        counts = {}\n",
    "        for document, category in zip(X, y):\n",
    "            for token in self.tokenize(document):\n",
    "                if token not in counts:\n",
    "                    counts[token] = [0,0]\n",
    "                counts[token][category] += 1\n",
    "        return counts\n",
    "\n",
    "    def prior_prob(self, counts):\n",
    "\n",
    "        cat0_word_count = cat1_word_count = 0\n",
    "        for word, (cat0_count, cat1_count) in counts.items():\n",
    "            cat0_word_count += cat0_count\n",
    "            cat1_word_count += cat1_count\n",
    "\n",
    "        self.cat0_count = cat0_word_count\n",
    "        self.cat1_count = cat1_word_count\n",
    "        self.total_count = self.cat0_count + self.cat1_count\n",
    "\n",
    "        cat_0_prior = cat0_word_count / self.total_count\n",
    "        cat_1_prior = cat1_word_count / self.total_count\n",
    "        return cat_0_prior, cat_1_prior\n",
    "\n",
    "    def word_probabilities(self, counts):\n",
    "       \n",
    "        self.vocab = [word for word, (cat0, cat1) in counts.items()]\n",
    "        return [(word,\n",
    "        (cat0 + self.k) / (self.cat0_count + 2 * self.k),\n",
    "        (cat1 + self.k) / (self.cat1_count + 2 * self.k))\n",
    "        for word, (cat0, cat1) in counts.items()]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        counts = self.count_words(X, y)\n",
    "        self.cat_0_prior, self.cat_1_prior = self.prior_prob(counts)\n",
    "        self.word_probs = self.word_probabilities(counts)\n",
    "\n",
    "    def predict(self, test_corpus):\n",
    "        \n",
    "        y_pred = []\n",
    "        for document in test_corpus:\n",
    "            log_prob_cat0 = log_prob_cat1 = 0.0\n",
    "            tokens = self.tokenize(document)\n",
    "            \n",
    "            for word, prob_cat0, prob_cat1 in self.word_probs:\n",
    "                if word in tokens:\n",
    "                    log_prob_cat0 += np.log(prob_cat0)\n",
    "                    log_prob_cat1 += np.log(prob_cat1)\n",
    "            cat_0_pred = self.cat_0_prior * np.exp(log_prob_cat0)\n",
    "            cat_1_pred = self.cat_1_prior * np.exp(log_prob_cat1)\n",
    "            if cat_0_pred >= cat_1_pred:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                y_pred.append(1)\n",
    "        return y_pred\n",
    "\n",
    "import re\n",
    "from math import log\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "# 定义Bernoulli model\n",
    "class Bernoulli:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._log_priors = None\n",
    "        self._cond_probs = None\n",
    "        self.features = None\n",
    "    \n",
    "    def fit(self, docs, labels):\n",
    "       \n",
    "        label_counts = Counter(labels)\n",
    "        N = float(sum(label_counts.values()))\n",
    "        self._log_priors = {k: log(v/N) for k, v in label_counts.items()}\n",
    "#         print(\"#####docs\",docs)\n",
    "        # 抽取 features \n",
    "        X = [set(self.get_features(d)) for d in docs]\n",
    "        # get all features\n",
    "        self.features = set([f for features in X for f in features])\n",
    "\n",
    "        #log( P(X|Y) )\n",
    "        #n1 + 1 / (n1 + n2 + 2)\n",
    "        self._cond_probs = {l: {f: 0. for f in self.features} for l in self._log_priors}\n",
    "\n",
    "        \n",
    "        for x, l in zip(X, labels):\n",
    "            for f in x:\n",
    "                self._cond_probs[l][f] += 1.\n",
    "\n",
    "        # 计算 log probs\n",
    "        for l in self._cond_probs:\n",
    "            N = label_counts[l]\n",
    "            self._cond_probs[l] = {f: (v + 1.) / (N + 2.) for f, v in self._cond_probs[l].items()}\n",
    "\n",
    "    def predict(self, docs):\n",
    "       \n",
    "        X = [set(self.get_features(d)) for d in docs]\n",
    "        y=[]\n",
    "        for x in X:\n",
    "            pred_class = None\n",
    "            max_ = float(\"-inf\")\n",
    "\n",
    "            # Perform MAP estimation\n",
    "            for l in self._log_priors:\n",
    "                log_sum = self._log_priors[l]\n",
    "                for f in self.features:\n",
    "                    prob = self._cond_probs[l][f]\n",
    "                    log_sum += log(prob if f in x else 1. - prob)\n",
    "                if log_sum > max_:\n",
    "                    max_ = log_sum\n",
    "                    pred_class = l\n",
    "            y.append(pred_class)\n",
    "        return y\n",
    "\n",
    "    #       转换特征\n",
    "    def get_features(self,text):\n",
    "        \n",
    "        return set([w.lower() for w in text.split(\" \")])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a11d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集准备\n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# gaussian 使用sklearn iris数据集\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6819a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn GaussianNB模型预测\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB ,MultinomialNB\n",
    "\n",
    "#GaussianNB\n",
    "skg=GaussianNB()\n",
    "skg.fit(X_train,y_train)\n",
    "skg_pre = skg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "195670a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用编写的 GaussianNB模型预测\n",
    "g=Gaussion()\n",
    "g.fit(X_train,y_train)\n",
    "g_pre = g.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "400bc6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      text                                                               \n",
      "     count unique                                                top freq\n",
      "spam                                                                     \n",
      "0     4825   4516                             Sorry, I'll call later   30\n",
      "1      747    653  Please call our customer service representativ...    4\n"
     ]
    }
   ],
   "source": [
    "# multiminol 使用 邮件数据集\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "spam = pd.read_csv(\"spam.csv\")\n",
    "dummies = pd.get_dummies(spam.label)\n",
    "spam = pd.concat([spam,dummies],axis=\"columns\")\n",
    "spam = spam.drop([\"label\",\"ham\"],axis=\"columns\")\n",
    "print(spam.groupby(\"spam\").describe())\n",
    "\n",
    "# print(spam)\n",
    "m_X_train, m_X_test, m_y_train, m_y_test = train_test_split(spam[\"text\"], spam[\"spam\"], test_size=0.5, random_state=0)\n",
    "# v=CountVectorizer(analyzer='word',ngram_range=(2,2))\n",
    "v=CountVectorizer(stop_words='english')\n",
    "\n",
    "m_X_train_T=v.fit_transform(m_X_train.values)\n",
    "m_X_test_T=v.transform(m_X_test.values)\n",
    "\n",
    "# print(m_X_train_T.toarray()[:1])\n",
    "# v.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d006d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB\n",
    "\n",
    "skm = MultinomialNB()\n",
    "skm.fit(m_X_train_T, m_y_train)\n",
    "skm_pre = skm.predict(m_X_test_T);\n",
    "\n",
    "# skm.score(m_X_train_T,m_y_test)\n",
    "# skm_pre.reshape(1,3)\n",
    "# m_X_test_T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用自编Multinomial\n",
    "m=Multinomial()\n",
    "m.fit(m_X_train, m_y_train)\n",
    "m_pre = m.predict(m_X_test)\n",
    "# m_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2ffb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bernoulli数据集，使用multiminal转换\n",
    "v=CountVectorizer(stop_words='english', binary=True)\n",
    "\n",
    "b_X_train_T=v.fit_transform(m_X_train.values).toarray()\n",
    "b_X_test_T=v.transform(m_X_test.values).toarray()\n",
    "b_y_train=m_y_train\n",
    "# print(b_X_train_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b1b88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skleran 实现，此处使用multiminal数据集\n",
    "skb = BernoulliNB()\n",
    "skb.fit(m_X_train_T, b_y_train)\n",
    "skb_pre = skb.predict(b_X_test_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b707d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自编bernuoulli\n",
    "alpha = 1\n",
    "b = Bernoulli()\n",
    "b.fit(m_X_train,m_y_train)\n",
    "# b.predict(m_X_test)\n",
    "b_pre = b.predict(m_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f2496b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk GaussianNB predict: [2 1 0 2 0 2 0 1 1 1 1 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 1 2]\n",
      "自编 Gaussion predict: [1 1 0 2 0 2 0 2 2 1 2 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 1 2]\n",
      "sk GaussianNB  accuracy_score:0.320\n",
      "自编 GaussianNB  accuracy_score:0.333\n",
      "\n",
      "\n",
      "sk MultinomialNB predict: [0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "自编 Multinomial predict: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "sk MultinomialNB  accuracy_score:0.772\n",
      "自编 MultinomialNB  accuracy_score:0.763\n",
      "\n",
      "\n",
      "sk BernoulliNB predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "自编 Bernoulli predict: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sk BernoulliNB  accuracy_score:0.806\n",
      "自编 BernoulliNB  accuracy_score:0.821\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def evaluate(typename,actual, pred):\n",
    "    m_accuracy_score = metrics.accuracy_score(actual,pred)\n",
    "    print(typename,' accuracy_score:{0:.3f}'.format(m_accuracy_score))\n",
    "\n",
    "# 对比分析\n",
    "print(\"sk GaussianNB predict:\",skg_pre[:50])\n",
    "print(\"自编 Gaussion predict:\",t[:50])\n",
    "evaluate(\"sk GaussianNB\",y_train,skg_pre)\n",
    "evaluate(\"自编 GaussianNB\",y_train,g_pre)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(\"sk MultinomialNB predict:\",skm_pre[:50])\n",
    "print(\"自编 Multinomial predict:\",m_pre[:50])\n",
    "evaluate(\"sk MultinomialNB\",m_y_train,skm_pre)\n",
    "evaluate(\"自编 MultinomialNB\",m_y_train,m_pre)\n",
    "\n",
    "print('\\n')\n",
    "print(\"sk BernoulliNB predict:\",skb_pre[:50])\n",
    "print(\"自编 Bernoulli predict:\",b_pre[:50])\n",
    "evaluate(\"sk BernoulliNB\",m_y_train,skb_pre)\n",
    "evaluate(\"自编 BernoulliNB\",m_y_train,b_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6be65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6e075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
